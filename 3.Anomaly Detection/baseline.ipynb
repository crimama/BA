{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch \n",
    "import torchvision \n",
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os \n",
    "import yaml \n",
    "import wandb  \n",
    "import json\n",
    "import argparse \n",
    "\n",
    "from src import Convolution_Auto_Encoder, Mnist_Dataset,MVtecADDataset,Datadir_init\n",
    "from src import MVtecEncoder,MVtecDecoder,Convolution_Auto_Encoder\n",
    "from src import Machine_Metric,Reconstruction_Metric\n",
    "from src import create_transformation\n",
    "from src.set_transformation import create_transformation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('-aug_number')\n",
    "    parser.add_argument('-save_dir')\n",
    "    args = parser.parse_args() \n",
    "    return args \n",
    "\n",
    "def preprocess(cfg,augmentation=None):\n",
    "    #mk save dir \n",
    "    try:\n",
    "        os.mkdir(f\"./Save_models/{cfg['save_dir']}\")\n",
    "    except:\n",
    "        pass\n",
    "    torch.manual_seed(cfg['seed'])\n",
    "    data_dir = cfg['Dataset_dir']\n",
    "    Data_dir = Datadir_init()\n",
    "    train_dirs = Data_dir.train_load()\n",
    "    test_dirs,test_labels = Data_dir.test_load()\n",
    "    indx = int(len(train_dirs)*0.8)\n",
    "\n",
    "    train_dset = MVtecADDataset(cfg,train_dirs[:indx],Augmentation=augmentation)\n",
    "    valid_dset = MVtecADDataset(cfg,train_dirs[indx:])\n",
    "    test_dset = MVtecADDataset(cfg,test_dirs,test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dset,batch_size=cfg['batch_size'],shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dset,batch_size=cfg['batch_size'],shuffle=False)\n",
    "    test_loader = DataLoader(test_dset,batch_size=cfg['batch_size'],shuffle=False)\n",
    "    return train_loader,valid_loader,test_loader \n",
    "\n",
    "def train_epoch(model,dataloader,criterion,optimizer,scheduler,scaler):\n",
    "       model.train()\n",
    "       optimizer.zero_grad()\n",
    "       train_loss = [] \n",
    "       for img,label in dataloader:\n",
    "              img = img.to(cfg['device']).type(torch.float32)\n",
    "              with torch.cuda.amp.autocast():\n",
    "                    y_pred = model(img).type(torch.float32)\n",
    "                    loss = torch.sqrt(criterion(img,y_pred))\n",
    "              #y_pred = model(img).type(torch.float32)\n",
    "              \n",
    "\n",
    "              #Backpropagation\n",
    "              scaler.scale(loss).backward()\n",
    "              scaler.step(optimizer)\n",
    "              scaler.update() \n",
    "              #loss.backward()\n",
    "              #optimizer.step()\n",
    "\n",
    "              #loss save \n",
    "              train_loss.append(loss.detach().cpu().numpy())\n",
    "       scheduler.step() \n",
    "       print(f'\\t epoch : {epoch+1} train loss : {np.mean(train_loss):.3f}')\n",
    "       return np.mean(train_loss)\n",
    "\n",
    "def valid_epoch(model,dataloader,criterion):\n",
    "       model.eval()\n",
    "       valid_loss = [] \n",
    "       with torch.no_grad():\n",
    "              for img,label in dataloader:\n",
    "                     img = img.to(cfg['device'])\n",
    "                     y_pred = model(img)\n",
    "                     loss = criterion(y_pred,img)\n",
    "                     valid_loss.append(loss.detach().cpu().numpy())\n",
    "       print(f'\\t epoch : {epoch+1} valid loss : {np.mean(valid_loss):.3f}')\n",
    "       fig, (ax1,ax2) = plt.subplots(ncols=2,nrows=1,figsize=(5, 5))\n",
    "       ax1.imshow(img[0].detach().cpu().permute(1,2,0).numpy())\n",
    "       ax2.imshow(y_pred[0].detach().cpu().permute(1,2,0).numpy())\n",
    "       plt.show()\n",
    "       return np.mean(valid_loss) \n",
    "\n",
    "def Save_result(cfg):\n",
    "\n",
    "    f = open(f\"./Save_models/{cfg['save_dir']}/config.yaml\",'w+')\n",
    "    yaml.dump(cfg, f, allow_unicode=True)\n",
    "    \n",
    "    metric =  {} \n",
    "    metric['auto'] = {} \n",
    "    metric['machine']={}\n",
    "\n",
    "    machine = Machine_Metric(cfg)\n",
    "    auto = Reconstruction_Metric(cfg)\n",
    "\n",
    "    [auroc,roc], [acc,pre,rec,f1] = machine.main()\n",
    "    [AUROC,ROC], [ACC,PRE,RECALL,F1] = auto.main() \n",
    "\n",
    "    metric['auto']['auroc'] = AUROC\n",
    "    metric['auto']['roc'] =  ROC \n",
    "    metric['auto']['metric'] =[ACC,PRE,RECALL,F1]\n",
    "    metric['machine']['roc'] = roc \n",
    "    metric['machine']['auroc']=auroc \n",
    "    metric['machine']['metric']=[acc,pre,rec,f1]\n",
    "\n",
    "\n",
    "    with open(f\"./Save_models/{cfg['save_dir']}/Metric.json\",'w') as f:\n",
    "       json.dump(metric,f)\n",
    "\n",
    "    return metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " args = parse_arguments()\n",
    "#init \n",
    "    cfg = yaml.load(open('./init_config.yaml','r'), Loader=yaml.FullLoader)\n",
    "    cfg['save_dir'] = args.save_dir\n",
    "    cfg['aug_number'] = int(args.aug_number)\n",
    "\n",
    "    trans = create_transformation(cfg)\n",
    "    wandb.init(project='BA_MVtec2',name=cfg['save_dir'])\n",
    "    wandb.config = cfg\n",
    "    train_loader,valid_loader,test_loader   = preprocess(cfg,trans)\n",
    "#trainig intit \n",
    "    model = Convolution_Auto_Encoder(MVtecEncoder,MVtecDecoder,cfg['encoded_space_dim']).to(cfg['device'])\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=cfg['lr'],weight_decay=cfg['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=100,eta_min=0)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "#Record \n",
    "    total_train_loss = [] \n",
    "    total_valid_loss = [] \n",
    "    best_valid_loss = np.inf \n",
    "    print('Training start')\n",
    "    for epoch in tqdm(range(cfg['Epochs'])):\n",
    "#training  \n",
    "        train_loss = train_epoch(model,train_loader,criterion,optimizer,scheduler,scaler)\n",
    "        valid_loss = valid_epoch(model,valid_loader,criterion)\n",
    "#logging \n",
    "        total_train_loss.append(train_loss)\n",
    "        total_valid_loss.append(valid_loss)\n",
    "        wandb.log({\"train_loss\":train_loss})\n",
    "        wandb.log({\"valid_loss\":valid_loss})\n",
    "\n",
    "#check point \n",
    "        if valid_loss < best_valid_loss:\n",
    "            torch.save(model,f\"./Save_models/{cfg['save_dir']}/best.pt\")\n",
    "            best_valid_loss = valid_loss \n",
    "            print(f'\\t Model save : {epoch} | best loss : {best_valid_loss :.3f}')\n",
    "\n",
    "#prevent explosion \n",
    "        if valid_loss != valid_loss:\n",
    "            model = torch.load(f\"./Save_models/{cfg['save_dir']}/best.pt\")\n",
    "            print('Model rewinded')\n",
    "\n",
    "#Save config \n",
    "    print('Training Done')\n",
    "\n",
    "    metric = Save_result(cfg)\n",
    "    print('Metric Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
