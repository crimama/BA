{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c73783-b040-4c48-a336-eb73d9886f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "from glob import glob \n",
    "import tqdm \n",
    "from PIL import Image \n",
    "from tqdm import tqdm \n",
    "import wandb\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "from src.Dataset import CifarDataset,label_unlabel_load,img_load_all\n",
    "from src.Models import Model,PiModel\n",
    "from src.Loss import PiCriterion\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3f49680-0d9d-4180-b365-04bb367ecce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform(cfg):\n",
    "    color_jitter = transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1)\n",
    "    label_transform = transforms.Compose([\n",
    "                                          transforms.RandomApply([color_jitter],p=0.8),\n",
    "                                          transforms.RandomResizedCrop(32),\n",
    "                                          transforms.GaussianBlur(kernel_size=int(0.1*32))\n",
    "                                         ])\n",
    "    return label_transform \n",
    "def make_valid(dataset = 'cifar10'):\n",
    "    (train_imgs,train_labels),(test_imgs,test_labels) = img_load_all(dataset)\n",
    "    idx = np.random.choice(np.arange(len(train_imgs)),5000,replace=False)\n",
    "    valid_set = {'imgs':train_imgs[idx],\n",
    "        'labels':train_labels[idx]}\n",
    "    return valid_set \n",
    "\n",
    "def train(model,criterion,optimizer,train_loader,cfg,transform):\n",
    "    global epoch \n",
    "    model.train() \n",
    "    tl_loss = [] \n",
    "    tu_loss = [] \n",
    "    epoch_loss = [] \n",
    "    for batch_img,batch_labels in tqdm(train_loader):\n",
    "        \n",
    "        batch_img_1 = transform(batch_img.type(torch.float32).to(cfg['device']))\n",
    "        batch_img_2 = transform(batch_img.type(torch.float32).to(cfg['device']))\n",
    "        batch_labels = batch_labels.to(cfg['device'])\n",
    "        \n",
    "        y_pred_1 = model(batch_img_1)\n",
    "        y_pred_2 = model(batch_img_2)\n",
    "        loss,tl,tu = criterion(y_pred_1,y_pred_2,batch_labels,epoch)\n",
    "        \n",
    "        epoch_loss.append(loss.detach().cpu().numpy())\n",
    "        tl_loss.append(tl.detach().cpu().numpy())\n",
    "        tu_loss.append(tu.detach().cpu().numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return np.mean(epoch_loss),np.mean(tl_loss),np.mean(tu_loss)\n",
    "\n",
    "def valid(model,test_loader,transform,cfg):\n",
    "    labels = []\n",
    "    y_preds = [] \n",
    "    model.eval() \n",
    "    for batch_imgs,batch_labels in test_loader:\n",
    "        batch_imgs = batch_imgs.type(torch.float32).to(cfg['device'])\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(batch_imgs)\n",
    "        y_pred = torch.argmax(F.softmax(y_pred),dim=1)\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "        \n",
    "        y_preds.extend(y_pred)\n",
    "        labels.extend(batch_labels.detach().cpu().numpy())    \n",
    "    f1 = f1_score(np.array(y_preds),np.array(labels),average='macro')\n",
    "    auc = accuracy_score(np.array(y_preds),np.array(labels))\n",
    "    return f1, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b77e991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 28.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epochs : 0\n",
      "\n",
      " loss : 1.9194456338882446 | tl_loss : 1.9194456338882446 | tu_loss : 0.0\n",
      "\n",
      " test f1 : 0.36534949682177015\n",
      "\n",
      " test auc : 0.4058\n",
      "model saved | best loss :1.9194456338882446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 113/500 [00:03<00:13, 28.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m best_epoch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minf \n\u001b[1;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cfg[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m---> 36\u001b[0m     loss,tl_loss,tu_loss \u001b[39m=\u001b[39m  train(model,criterion,optimizer,train_loader,cfg,tl_transform)\n\u001b[1;32m     37\u001b[0m     f1 , auc \u001b[39m=\u001b[39m valid(model,valid_loader,tl_transform,cfg)\n\u001b[1;32m     38\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epochs : \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [28], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, cfg, transform)\u001b[0m\n\u001b[1;32m     20\u001b[0m epoch_loss \u001b[39m=\u001b[39m [] \n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m batch_img,batch_labels \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[0;32m---> 23\u001b[0m     batch_img_1 \u001b[39m=\u001b[39m transform(batch_img\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mfloat32)\u001b[39m.\u001b[39;49mto(cfg[\u001b[39m'\u001b[39;49m\u001b[39mdevice\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m     24\u001b[0m     batch_img_2 \u001b[39m=\u001b[39m transform(batch_img\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(cfg[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m     25\u001b[0m     batch_labels \u001b[39m=\u001b[39m batch_labels\u001b[39m.\u001b[39mto(cfg[\u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "cfg = {}\n",
    "cfg['dataset'] = 'cifar10'\n",
    "cfg['model_name'] = 'resnet18'\n",
    "cfg['unlabel_ratio'] = 0\n",
    "cfg['batch_size'] = 100 \n",
    "cfg['device'] = 'cuda:0'\n",
    "cfg['lr'] = 0.003 \n",
    "cfg['beta1'] = 0.8\n",
    "cfg['beta2'] = 0.999 \n",
    "cfg['epochs'] = 300 \n",
    "cfg['std'] = 0.15 \n",
    "\n",
    "\n",
    "\n",
    "train_set,test_set = label_unlabel_load(cfg)\n",
    "valid_set = make_valid()\n",
    "train_dataset = CifarDataset(train_set, unlabel=False)\n",
    "valid_dataset = CifarDataset(valid_set, unlabel=False)\n",
    "test_dataset = CifarDataset(test_set,unlabel=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=cfg['batch_size'],shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset,batch_size=cfg['batch_size'],shuffle=False)\n",
    "test_loader = DataLoader(test_dataset,batch_size=cfg['batch_size'],shuffle=False)\n",
    "\n",
    "tl_transform= make_transform(cfg)\n",
    "\n",
    "#model = PiModel(device='cuda')\n",
    "model = Model(cfg['model_name']).to('cuda')\n",
    "criterion = PiCriterion()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=cfg['lr'],betas=(cfg['beta1'],cfg['beta2']))\n",
    "\n",
    "\n",
    "\n",
    "best_epoch = np.inf \n",
    "for epoch in range(cfg['epochs']):\n",
    "    loss,tl_loss,tu_loss =  train(model,criterion,optimizer,train_loader,cfg,tl_transform)\n",
    "    f1 , auc = valid(model,valid_loader,tl_transform,cfg)\n",
    "    print(f'\\n Epochs : {epoch}')\n",
    "    print(f'\\n loss : {loss} | tl_loss : {tl_loss} | tu_loss : {tu_loss}')\n",
    "    print(f'\\n test f1 : {f1}')\n",
    "    print(f'\\n test auc : {auc}')\n",
    "    \n",
    "    if loss < best_epoch:\n",
    "        torch.save(model,'./Save_models/best.pt')\n",
    "        best_epoch = loss \n",
    "        print(f'model saved | best loss :{best_epoch}')\n",
    "\n",
    "    #if  loss > 10000:\n",
    "     #   model = torch.load('./Save_models/best.pt')\n",
    "      #  print('Model reloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da91061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5104111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
