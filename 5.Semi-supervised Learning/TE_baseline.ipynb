{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.gridspec as gsp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tf\n",
    "\n",
    "\n",
    "class GaussianNoise(nn.Module):\n",
    "    \n",
    "    def __init__(self, batch_size, input_shape=(1, 28, 28), std=0.05):\n",
    "        super(GaussianNoise, self).__init__()\n",
    "        self.shape = (batch_size,) + input_shape\n",
    "        self.noise = Variable(torch.zeros(self.shape).cuda())\n",
    "        self.std = std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.noise.data.normal_(0, std=self.std)\n",
    "        return x + self.noise\n",
    "\n",
    "\n",
    "def prepare_mnist():\n",
    "    # normalize data\n",
    "    m = (0.1307,)\n",
    "    st = (0.3081,)\n",
    "    normalize = tf.Normalize(m, st)\n",
    "        \n",
    "    # load train data\n",
    "    train_dataset = datasets.MNIST(\n",
    "                        root='../data', \n",
    "                        train=True, \n",
    "                        transform=tf.Compose([tf.ToTensor(), normalize]),  \n",
    "                        download=True)\n",
    "    \n",
    "    # load test data\n",
    "    test_dataset = datasets.MNIST(\n",
    "                        root='../data', \n",
    "                        train=False, \n",
    "                        transform=tf.Compose([tf.ToTensor(), normalize]))\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def ramp_up(epoch, max_epochs, max_val, mult):\n",
    "    if epoch == 0:\n",
    "        return 0.\n",
    "    elif epoch >= max_epochs:\n",
    "        return max_val\n",
    "    return max_val * np.exp(mult * (1. - float(epoch) / max_epochs) ** 2)\n",
    "\n",
    "\n",
    "def weight_schedule(epoch, max_epochs, max_val, mult, n_labeled, n_samples):\n",
    "    max_val = max_val * (float(n_labeled) / n_samples)\n",
    "    return ramp_up(epoch, max_epochs, max_val, mult)\n",
    "\n",
    "\n",
    "def calc_metrics(model, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (samples, labels) in enumerate(loader):\n",
    "        samples = Variable(samples.cuda(), volatile=True)\n",
    "        labels = Variable(labels.cuda())\n",
    "        outputs = model(samples)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data.view_as(predicted)).sum()\n",
    "\n",
    "    acc = 100 * float(correct) / total\n",
    "    return acc\n",
    "\n",
    "\n",
    "def savetime():\n",
    "    return datetime.now().strftime('%Y_%m_%d_%H%M%S')\n",
    "\n",
    "\n",
    "def save_losses(losses, sup_losses, unsup_losses, fname, labels=None):\n",
    "    plt.style.use('ggplot')\n",
    "    \n",
    "    # color palette from Randy Olson\n",
    "    colors = [\n",
    "        (31, 119, 180),\n",
    "        (174, 199, 232),\n",
    "        (255, 127, 14), \n",
    "        (255, 187, 120),    \n",
    "        (44, 160, 44),\n",
    "        (152, 223, 138),\n",
    "        (214, 39, 40),\n",
    "        (255, 152, 150),    \n",
    "        (148, 103, 189),\n",
    "        (197, 176, 213), \n",
    "        (140, 86, 75),\n",
    "        (196, 156, 148),    \n",
    "        (227, 119, 194),\n",
    "        (247, 182, 210),\n",
    "        (127, 127, 127),\n",
    "        (199, 199, 199),    \n",
    "        (188, 189, 34),\n",
    "        (219, 219, 141),\n",
    "        (23, 190, 207),\n",
    "        (158, 218, 229)]\n",
    "\n",
    "    colors = [(float(c[0]) / 255, float(c[1]) / 255, float(c[2]) / 255) for c in colors]\n",
    "\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(12, 18))\n",
    "    for i in range(3):\n",
    "        axs[i].tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",    \n",
    "                           labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "    for i in range(len(losses)):\n",
    "        axs[0].plot(losses[i], color=colors[i])\n",
    "        axs[1].plot(sup_losses[i], color=colors[i])\n",
    "        axs[2].plot(unsup_losses[i], color=colors[i])\n",
    "    axs[0].set_title('Overall loss', fontsize=14)\n",
    "    axs[1].set_title('Supervised loss', fontsize=14)\n",
    "    axs[2].set_title('Unsupervised loss', fontsize=14)\n",
    "    if labels is not None:\n",
    "        axs[0].legend(labels)\n",
    "        axs[1].legend(labels)\n",
    "        axs[2].legend(labels)\n",
    "    plt.savefig(fname)\n",
    "\n",
    "\n",
    "def save_exp(time, losses, sup_losses, unsup_losses,\n",
    "             accs, accs_best, idxs, **kwargs):\n",
    "    \n",
    "    def save_txt(fname, accs, **kwargs):\n",
    "        with open(fname, 'w') as fp:\n",
    "            fp.write('GLOB VARS\\n')\n",
    "            fp.write('n_exp        = {}\\n'.format(kwargs['n_exp']))\n",
    "            fp.write('k            = {}\\n'.format(kwargs['k']))\n",
    "            fp.write('MODEL VARS\\n')\n",
    "            fp.write('drop         = {}\\n'.format(kwargs['drop']))\n",
    "            fp.write('std          = {}\\n'.format(kwargs['std']))\n",
    "            fp.write('fm1          = {}\\n'.format(kwargs['fm1']))\n",
    "            fp.write('fm2          = {}\\n'.format(kwargs['fm2']))\n",
    "            fp.write('w_norm       = {}\\n'.format(kwargs['w_norm']))\n",
    "            fp.write('OPTIM VARS\\n')\n",
    "            fp.write('lr           = {}\\n'.format(kwargs['lr']))\n",
    "            fp.write('beta2        = {}\\n'.format(kwargs['beta2']))\n",
    "            fp.write('num_epochs   = {}\\n'.format(kwargs['num_epochs']))\n",
    "            fp.write('batch_size   = {}\\n'.format(kwargs['batch_size']))\n",
    "            fp.write('TEMP ENSEMBLING VARS\\n')\n",
    "            fp.write('alpha        = {}\\n'.format(kwargs['alpha']))\n",
    "            fp.write('data_norm    = {}\\n'.format(kwargs['data_norm']))\n",
    "            fp.write('divide_by_bs = {}\\n'.format(kwargs['divide_by_bs']))\n",
    "            fp.write('\\nRESULTS\\n')\n",
    "            fp.write('best accuracy : {}\\n'.format(np.max(accs)))\n",
    "            fp.write('accuracy : {} (+/- {})\\n'.format(np.mean(accs), np.std(accs)))\n",
    "            fp.write('accs : {}\\n'.format(accs))\n",
    "        \n",
    "    labels = ['seed_' + str(sd) for sd in kwargs['seeds']]\n",
    "    if not os.path.isdir('exps'):\n",
    "        os.mkdir('exps')\n",
    "    time_dir = os.path.join('exps', time)\n",
    "    if not os.path.isdir(time_dir):\n",
    "        os.mkdir(time_dir)\n",
    "    fname_bst = os.path.join('exps', time, 'training_best.png')\n",
    "    fname_fig = os.path.join('exps', time, 'training_all.png')\n",
    "    fname_smr = os.path.join('exps', time, 'summary.txt')\n",
    "    fname_sd  = os.path.join('exps', time, 'seed_samples')\n",
    "    best = np.argmax(accs_best)\n",
    "    save_losses([losses[best]], [sup_losses[best]], [unsup_losses[best]], fname_bst)\n",
    "    save_losses(losses, sup_losses, unsup_losses, fname_fig, labels=labels)\n",
    "    for seed, indices in zip(kwargs['seeds'], idxs):\n",
    "        save_seed_samples(fname_sd + '_seed' + str(seed) + '.png', indices)\n",
    "    save_txt(fname_smr, accs_best, **kwargs)\n",
    "\n",
    "\n",
    "def save_seed_samples(fname, indices):\n",
    "    train_dataset, test_dataset = prepare_mnist()\n",
    "    imgs = train_dataset.train_data[indices.numpy().astype(int)]\n",
    "    \n",
    "    plt.style.use('classic')\n",
    "    fig = plt.figure(figsize=(15, 60))\n",
    "    gs = gsp.GridSpec(20, 5, width_ratios=[1, 1, 1, 1, 1],\n",
    "                      wspace=0.0, hspace=0.0)\n",
    "    for ll in range(100):\n",
    "        i = ll // 5\n",
    "        j = ll % 5\n",
    "        img = imgs[ll].numpy()\n",
    "        ax = plt.subplot(gs[i, j])\n",
    "        ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",\n",
    "                       labelbottom=\"off\", left=\"off\", right=\"off\", labelleft=\"off\")\n",
    "        ax.imshow(img)\n",
    "    \n",
    "    plt.savefig(fname)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
